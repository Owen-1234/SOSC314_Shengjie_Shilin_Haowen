
# SOSC314: Narrative Competition in Global Energy Transition

### A Cross-National Media Analysis (2020-2026)

## ðŸš€ Project Overview

This project is the final capstone for SOSC 314: Computational Social Science at Duke Kunshan University. It explores the "narrative divide" between Western and Chinese media regarding climate policy and energy transition. By leveraging 7,000 news articles, we investigate how different national entities use language to frame responsibility, energy security, and the transition to a low-carbon future.

---

## ðŸ”— Quick Links

* **[Dataset](https://github.com/Owen-1234/SOSC314_Shengjie_Shilin_Haowen/tree/main/Data)**: 7,000+ processed articles and Weighted Frequency results
* **[Code](https://github.com/Owen-1234/SOSC314_Shengjie_Shilin_Haowen/tree/main/Code)**: Scripts for Context Extraction (Sliding Window), Data Cleaning, and **STM Modeling (R)**.
* **[Visualizations](https://github.com/Owen-1234/SOSC314_Shengjie_Shilin_Haowen/tree/main/Image)**: High-res narrative comparison charts and Word Clouds.

---

## ðŸ“Š Narrative Frequency Analysis & Measurement

To ensure a fair comparison between the Chinese corpus (5,000 articles) and the Western corpus (2,000 articles), we implemented a Weighted Measurement Strategy.

Instead of raw counts, we calculate the density of a concept per 1,000 articles:

### Context Extraction (Sliding Window)

We developed a Python-based **Context Extraction** script that captures all tokens within a 20-word radius of our core seed terms (*Energy Transition*, *Carbon Neutrality*, *Climate Policy*). This allows us to filter out general news noise and focus exclusively on the conceptual vocabulary surrounding energy topics.

---

## Â Dirichlet Multinomial Regression & Comparative Analysis

In the final phase of our analysis, we implemented a **DMR (Dirichlet Multinomial Regression)** model to quantify the narrative divergence. After testing , we determined **** to be the optimal granularity, providing the best balance between statistical fit (Log-Likelihood) and semantic distinctness.

### ðŸ¤– Structural Topic Modeling (STM) Implementation

In addition to DMR, we utilized an **R-based STM pipeline** to further investigate how metadata influences topic prevalence.

* **Model Configuration**: We fitted an STM with **K=20** topics using **Spectral initialization**.
* **Prevalence Covariates**: The model estimates topic proportions based on:
`Prevalence ~ media + source + keyword + s(year)`
*The inclusion of `s(year)` (a spline function) allows us to capture the non-linear evolution of energy narratives over the 2020-2026 period.*
* **Statistical Outputs**: We exported the **Theta matrix** to calculate the mean topic proportions across different media systems, enabling a rigorous comparative analysis.

### Advanced Quantified Visualizations

We decoded the energy discourse using two specialized computational social science visualizations:

#### 1. Topic Correlation Network (`topic_network_map.png`)

This graph visualizes the "Narrative Web" by calculating the semantic connectivity (keyword overlap) between topics.

* **Key Finding:** It reveals how *Renewable Energy* is structurally tied to *National Innovation* in the merged global discourse, forming a central narrative hub.

#### 2. Region-Specific Mirror Analysis (`region_specific_mirror_plot.png`)

Using a **Lexical Exclusivity Score**, this "Tornado Plot" identifies topics and keywords that are unique to each media group.

* **China-Specific:** High exclusivity in topics involving `cpc, committee, modernization`, indicating a **State-led/Institutionalized** narrative.
* **UK-Specific:** High exclusivity in topics involving `trump, biden, court, labor`, indicating a **Party-politics/Politicized** narrative.

---

## Methodology & Tech Stack

1. **Automated Collection:** Using `gdeltdoc` and `newspaper3k`.
2. **Standardized Measurement:** Weighted frequency normalization to balance corpus sizes.
3. **Context Mining:** Proximity-based extraction (20-word window) for narrative precision.
4. **Topic Modeling:** Combined **DMR** (Python) and **Structural Topic Modeling** (R, `stm` package) for cross-verifying topic prevalence.
5. **Visualization:** Matplotlib, Seaborn, NetworkX, and R's `ggplot2` for quantitative plotting.

---

## Â Repository Structure

```text
â”œâ”€â”€ Data/
â”‚ Â  â”œâ”€â”€ energy_narrative_C_cleaned.csv Â  Â  Â  Â  Â  Â  Â # Cleaned Chinese data
â”‚ Â  â”œâ”€â”€ energy_narrative_W_cleaned.csv Â  Â  Â  Â  Â  Â  Â # Cleaned Western data
â”‚ Â  â”œâ”€â”€ Frequency.csv Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Word density results
â”‚ Â  â””â”€â”€ STM_topic_comparison.csv Â  Â  Â  Â  Â  Â  Â  Â  Â  Â # Topic keywords for K=10, 20, 30
â”œâ”€â”€ Code/
â”‚ Â  â”œâ”€â”€ 01_DataGathering.ipynb
â”‚ Â  â”œâ”€â”€ 02_DataCleaning.ipynb
â”‚ Â  â”œâ”€â”€ 03_ContextExtraction.ipynb Â  Â  Â  Â  Â  Â  Â  Â  Â # Context-aware keyword mining
â”‚ Â  â”œâ”€â”€ 04_Frequency_Visualization.ipynb Â  Â  Â  Â  Â  Â # Standardized bar charts
â”‚ Â  â”œâ”€â”€ 05_DMR_Modeling.py Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â # DMR Model training logic
â”‚ Â  â”œâ”€â”€ 06_DMR_Advanced_Visualization.py Â  Â  Â  Â  Â  Â # Network & Mirror plot scripts
â”‚ Â  â””â”€â”€ 07_STM.Rmd Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â # STM implementation in R (K=20)
â”œâ”€â”€ stm_outputs_R_K20/ Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â # Generated by R script
â”‚ Â  â”œâ”€â”€ K20_top_words.txt Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Topic words & labels
â”‚ Â  â”œâ”€â”€ K20_theta.csv Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Document-topic distribution
â”‚ Â  â””â”€â”€ K20_mean_theta_by_media.csv Â  Â  Â  Â  Â  Â  Â  Â  # Regional mean proportions
â”œâ”€â”€ Image/
â”‚ Â  â”œâ”€â”€ WordCloud.png
â”‚ Â  â”œâ”€â”€ Frequency.png Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Standardized comparison chart
â”‚ Â  â”œâ”€â”€ topic_network_map.png Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Topic correlation graph
â”‚ Â  â””â”€â”€ region_specific_mirror_plot.png Â  Â  Â  Â  Â  Â  # Regional exclusivity comparison
â””â”€â”€ README.md

```
